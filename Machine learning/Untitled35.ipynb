{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce484079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import pygame\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set the window size and title\n",
    "pygame.display.set_mode((800, 600))\n",
    "pygame.display.set_caption(\"SET YOUR HAIR\")\n",
    "\n",
    "# Load the song\n",
    "song_path = r\"C:\\Users\\sharm\\Music\\old_SOTY-Ishq Wala Love.mp3\"\n",
    "pygame.mixer.music.load(song_path)\n",
    "\n",
    "# Initialize the hand detector\n",
    "detector = HandDetector(detectionCon=0.8)\n",
    "\n",
    "# Shahrukh Khan's iconic pose landmarks (wrist, elbow, and shoulder)\n",
    "pose_landmarks = [4, 5, 6]\n",
    "\n",
    "# Main loop\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Read the frame from the camera\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Detect hands in the frame\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    hands, _ = detector.findHands(frame)\n",
    "\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        landmarks = hand[\"lmList\"]\n",
    "        fingers = detector.fingersUp(hand)\n",
    "\n",
    "        # Check if the hand is in Shahrukh Khan's iconic pose\n",
    "        if all(landmarks[i][2] > landmarks[i + 1][2] for i in pose_landmarks) and all(fingers):\n",
    "            # Play the song\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "            # Display a message on the frame\n",
    "            cvzone.cornerRect(frame, (20, 20, 180, 80), 20, rt=0)\n",
    "            cv2.putText(frame, \"Set your hair\", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Shahrukh Khan Iconic Pose Detection\", frame)\n",
    "\n",
    "    # Check for key press events\n",
    "    if cv2.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd31812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the movie reviews dataset\n",
    "data = pd.read_csv(\"movie_reviews.csv\")  # Replace with the actual path to your dataset\n",
    "\n",
    "# Preprocess the data\n",
    "reviews = data[\"review\"].values\n",
    "labels = data[\"sentiment\"].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_reviews, test_reviews, train_labels, test_labels = train_test_split(reviews, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the reviews\n",
    "tokenizer = Tokenizer(num_words=10000)  # Limit vocabulary size to the top 10,000 words\n",
    "tokenizer.fit_on_texts(train_reviews)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_reviews)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_reviews)\n",
    "\n",
    "# Pad the sequences\n",
    "max_sequence_length = 100  # Limit the maximum sequence length to 100 words\n",
    "train_data = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=max_sequence_length),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=5, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"sentiment_analysis_model.h5\")\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2127c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b15b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45136bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fd400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0fda6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

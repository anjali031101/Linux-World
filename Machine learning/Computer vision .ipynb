{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef10dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import turtle\n",
    "import pyautogui\n",
    "import pygame\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import model_from_json\n",
    "import cv2\n",
    "import copy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import tkinter as tk\n",
    "import joblib as jb\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb12cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Task Menu\")\n",
    "window_width = 400\n",
    "window_height = 300\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "x_coordinate = int((screen_width - window_width) / 2)\n",
    "y_coordinate = int((screen_height - window_height) / 2)\n",
    "root.geometry(f\"{window_width}x{window_height}+{x_coordinate}+{y_coordinate}\")\n",
    "\n",
    "# Set the background color of the Tkinter window\n",
    "root.configure(bg=\"lightgray\")\n",
    "\n",
    "# Create a label to display the menu options\n",
    "label = tk.Label(root, text=\"Team 11 \\nSelect a task:\", bg=\"lightgray\")\n",
    "label.pack()\n",
    "# Create a variable to hold the user's choice\n",
    "choice_var = tk.StringVar()\n",
    "\n",
    "# Create check buttons for the user to select a task\n",
    "tk.Checkbutton(root, text=\"Goggles\", variable=choice_var, onvalue=\"1\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "tk.Checkbutton(root, text=\"Blurr Face\", variable=choice_var, onvalue=\"2\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "tk.Checkbutton(root, text=\"Bunny\", variable=choice_var, onvalue=\"3\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "tk.Checkbutton(root, text=\"Distance\", variable=choice_var, onvalue=\"4\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "tk.Checkbutton(root, text=\"Cropped\", variable=choice_var, onvalue=\"5\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "tk.Checkbutton(root, text=\"Happy\", variable=choice_var, onvalue=\"6\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "tk.Checkbutton(root, text=\"VirtualMouse\", variable=choice_var, onvalue=\"7\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "tk.Checkbutton(root, text=\"BackBlur\", variable=choice_var, onvalue=\"8\", offvalue=\"\", bg=\"lightgray\").pack(anchor=tk.W)\n",
    "\n",
    "\n",
    "\n",
    "# Create a button to execute the selected task\n",
    "execute_button = tk.Button(root, text=\"Execute Task\", command=execute_selected_task, bg=\"blue\", fg=\"white\")\n",
    "execute_button.pack()\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80bcd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d795fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_selected_task():\n",
    "    selected_task = int(choice_var.get())\n",
    "    if selected_task == 1:\n",
    "        goggles()\n",
    "    elif selected_task ==2:\n",
    "        BlurrFace()\n",
    "    elif selected_task ==3:\n",
    "        Bunny()\n",
    "    elif selected_task ==4:\n",
    "        Distance()\n",
    "    elif selected_task ==5:\n",
    "        Cropped()\n",
    "    elif selected_task == 6:\n",
    "        Happy()\n",
    "    elif selected_task == 7:\n",
    "        VirtualMouse()\n",
    "    elif selected_task == 8:\n",
    "        BackBlur()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc8f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goggles():\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    cap= cv2.VideoCapture(0)\n",
    "    # Load the face cascade XML file for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascase.xml')\n",
    "\n",
    "    # Load the goggles image with transparency\n",
    "    goggles_img = cv2.imread('heart.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    while True:\n",
    "        # Read the current frame from the video stream\n",
    "        status, photo = cap.read()\n",
    "\n",
    "        if not status:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(photo, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Calculate the position and size of the face region\n",
    "            face_roi = photo[y:y + h, x:x + w]\n",
    "\n",
    "            # Resize the goggles image to match the dimensions of the face region\n",
    "            goggles_resized = cv2.resize(goggles_img, (w, h))\n",
    "\n",
    "            # Extract the alpha channel of the goggles image\n",
    "            alpha = goggles_resized[:, :, 3] / 255.0\n",
    "\n",
    "            # Create a mask for the goggles region\n",
    "            mask = alpha.astype(np.uint8)\n",
    "\n",
    "            # Apply the mask to remove the goggles region from the face\n",
    "            bg_removed = cv2.bitwise_and(face_roi, face_roi, mask=(1 - mask))\n",
    "\n",
    "            # Overlay the resized goggles image onto the face region\n",
    "            output = bg_removed + cv2.bitwise_and(goggles_resized[:, :, :3], goggles_resized[:, :, :3], mask=mask)\n",
    "\n",
    "            # Replace the face region with the modified output\n",
    "            photo[y:y + h, x:x + w] = output\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            #cv2.rectangle(photo, (x, y), (x + w, y + h), [0, 255, 0], 5)\n",
    "\n",
    "        # Display the modified frame\n",
    "        cv2.imshow(\"Video\", photo)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(10) == 13:\n",
    "            break\n",
    "\n",
    "    # Release the video capture and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a3c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BlurrFace():\n",
    "#face blur\n",
    "    import cv2\n",
    "\n",
    "    # Load the Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascase.xml')\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read the frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the grayscale frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the region of interest (face) from the frame\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Apply a blur effect to the surrounding area of the face\n",
    "            blurred = cv2.GaussianBlur(frame, (99, 99), 0)\n",
    "\n",
    "            # Replace the surrounding area of the face with the blurred frame\n",
    "            frame[y:y+h, x:x+w] = blurred[y:y+h, x:x+w]\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Face Detection with Blur', frame)\n",
    "\n",
    "        # Exit the loop if the 'q' key is pressed\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "586fc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bunny():\n",
    "    import cv2\n",
    "    cap= cv2.VideoCapture(0)\n",
    "    status ,photo = cap.read() \n",
    "\n",
    "    # Load the cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascase.xml')\n",
    "\n",
    "    # Load the bunny face image with an alpha channel\n",
    "    bunny_face = cv2.imread('bunny.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # Extract the bunny face and the alpha channel\n",
    "    bunny_face_image = bunny_face[:, :, :3]\n",
    "    bunny_face_mask = bunny_face[:, :, 3]\n",
    "\n",
    "    # Initialize the video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read the frame from the video capture\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Iterate over the detected faces\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Resize the bunny face to match the size of the detected face\n",
    "            resized_bunny_face = cv2.resize(bunny_face_image, (w, h))\n",
    "            resized_bunny_mask = cv2.resize(bunny_face_mask, (w, h))\n",
    "\n",
    "            # Apply the bunny face mask to create a region of interest (ROI)\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            roi_bunny = cv2.bitwise_and(resized_bunny_face, resized_bunny_face, mask=resized_bunny_mask)\n",
    "\n",
    "            # Add the bunny face to the ROI\n",
    "            bunny_face_final = cv2.add(roi, roi_bunny)\n",
    "\n",
    "            # Update the frame with the bunny face\n",
    "            frame[y:y+h, x:x+w] = bunny_face_final\n",
    "\n",
    "            # Add text \n",
    "            cv2.putText(frame, 'Hey People ', (x, y-10), cv2.FONT_HERSHEY_DUPLEX, 0.9, (203, 192, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "\n",
    "    # Release the video capture\n",
    "    cap.release()\n",
    "\n",
    "    # Destroy all windows\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c760a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Distance():\n",
    "    import cv2\n",
    "    import math\n",
    "\n",
    "    # Load the Haar Cascade classifier\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascase.xml')\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Constants for distance measurement\n",
    "    KNOWN_DISTANCE = 100  # Define a known distance (in cm) from the camera to the face\n",
    "    KNOWN_FACE_WIDTH = 15  # Define the width of the face (in cm) at the known distance\n",
    "\n",
    "    while True:\n",
    "        # Read the frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the grayscale frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Calculate the distance to the face using the known distance and face width\n",
    "            face_width_pixels = w\n",
    "            distance = (KNOWN_FACE_WIDTH * cap.get(3)) / (2 * face_width_pixels * math.tan(cap.get(4) * math.pi / 360))\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            # Draw the distance on the frame\n",
    "            cv2.putText(frame, f\"Distance: {distance:.2f} cm\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with distance information\n",
    "        cv2.imshow('Distance Measurement', frame)\n",
    "\n",
    "        # Exit the loop if the 'q' key is pressed\n",
    "        if cv2.waitKey(1)==13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fde95f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cropped():\n",
    "    import cv2\n",
    "\n",
    "    # Load the Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascase.xml')\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read the frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the grayscale frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Crop the detected face from the frame\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Display the cropped face in a separate window\n",
    "            cv2.imshow('Detected Face', face)\n",
    "\n",
    "            # Draw a rectangle around the detected face in the original frame\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with detected faces\n",
    "        cv2.imshow('Face Detection', frame)\n",
    "\n",
    "        # Exit the loop if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) ==13:\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2c3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Happy():\n",
    "    import turtle\n",
    "    import pygame\n",
    "\n",
    "    # Initialize Pygame\n",
    "    pygame.init()\n",
    "\n",
    "    # Set up the screen\n",
    "    screen = turtle.Screen()\n",
    "    screen.title(\"Doraemon Drawing and Song\")\n",
    "    screen.bgcolor(\"white\")\n",
    "\n",
    "    # Set up the turtle\n",
    "    t = turtle.Turtle()\n",
    "    t.speed(3)\n",
    "\n",
    "    # Draw head\n",
    "    t.penup()\n",
    "    t.goto(0, -100)\n",
    "    t.pendown()\n",
    "    t.circle(100)\n",
    "\n",
    "    # Draw body\n",
    "    t.penup()\n",
    "    t.goto(0, -200)\n",
    "    t.pendown()\n",
    "    t.circle(150)\n",
    "\n",
    "    # Draw eyes\n",
    "    t.penup()\n",
    "    t.goto(-40, 30)\n",
    "    t.pendown()\n",
    "    t.begin_fill()\n",
    "    t.circle(15)\n",
    "    t.end_fill()\n",
    "\n",
    "    t.penup()\n",
    "    t.goto(40, 30)\n",
    "    t.pendown()\n",
    "    t.begin_fill()\n",
    "    t.circle(15)\n",
    "    t.end_fill()\n",
    "\n",
    "    # Draw mouth\n",
    "    t.penup()\n",
    "    t.goto(-40, -10)\n",
    "    t.pendown()\n",
    "    t.setheading(-60)\n",
    "    t.circle(40, 120)\n",
    "\n",
    "    # Draw Doraemon's song\n",
    "    t.penup()\n",
    "    t.goto(-70, 130)\n",
    "    t.pendown()\n",
    "    t.write(\"Cheers to the wonderful 45 days journey💗\", font=(\"Arial\", 16, \"bold\"))\n",
    "\n",
    "    # Hide the turtle\n",
    "    t.hideturtle()\n",
    "\n",
    "    # Play the Doraemon song\n",
    "    pygame.mixer.music.load(\"Happy Happy - Cat Meme Song.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Exit on screen click\n",
    "    screen.exitonclick()\n",
    "\n",
    "    # Quit Pygame\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a7d3c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VirtualMouse():\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import pyautogui\n",
    "    from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 1280)\n",
    "    cap.set(4, 720)\n",
    "\n",
    "    detector = HandDetector(detectionCon=0.8, maxHands=1)\n",
    "\n",
    "    screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        hands, frame = detector.findHands(frame)\n",
    "\n",
    "        if hands:\n",
    "            hand = hands[0]\n",
    "            lmList, bbox = hand[\"lmList\"], hand[\"bbox\"]\n",
    "            center_x, center_y = int((bbox[0] + bbox[2]) // 2), int((bbox[1] + bbox[3]) // 2)\n",
    "\n",
    "            fingers = detector.fingersUp(hand)\n",
    "            total_fingers = fingers.count(1)\n",
    "\n",
    "            # Move mouse cursor\n",
    "            mouse_x = np.interp(center_x, [0, screen_width], [0, screen_width])\n",
    "            mouse_y = np.interp(center_y, [0, screen_height], [0, screen_height])\n",
    "            pyautogui.moveTo(mouse_x, mouse_y, duration=0.1)\n",
    "\n",
    "            # Perform click actions\n",
    "            if total_fingers == 1:\n",
    "                pyautogui.mouseDown()\n",
    "\n",
    "            if total_fingers == 0:\n",
    "                pyautogui.mouseUp()\n",
    "\n",
    "        cv2.imshow(\"Hand Tracking\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31d13fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackBlur():\n",
    "    import cv2\n",
    "\n",
    "    # Load the Haar Cascade classifier for face detection\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascase.xml')\n",
    "\n",
    "    # Open the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read the frame from the webcam\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the grayscale frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Apply a blur effect to the background\n",
    "        blurred = cv2.GaussianBlur(frame, (99, 99), 0)\n",
    "\n",
    "        # Process each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Extract the region of interest (face) from the frame\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Replace the face region with the original, unblurred face\n",
    "            blurred[y:y+h, x:x+w] = face\n",
    "\n",
    "        # Display the result\n",
    "        cv2.imshow('Background Blur with Visible Face', blurred)\n",
    "\n",
    "        # Exit the loop if the 'q' key is pressed\n",
    "        if cv2.waitKey(1) ==13:\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close all windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880687c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6e97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1982ec54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
